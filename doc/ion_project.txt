This file contains instructions and notes about the Ion CPU core project.
The core structure is briefly explained in section 2. The rest of this doc is 
mostly usage instructions for the test samples and custom utilities.
In its present state it' more a reminder to myself than a proper explaination of
the system.

Last modified: Apr/04/2011

TO BE DONE: Some stub cache timing diagrams still missing.

Send bug reports or comments to ja_rd[at]hotmail[dot]com




1.- Introduction
================================================================================

    This is a MIPS-I compatible CPU, aiming at compatibility with IDT's R3000 
    MIPS derivative.

1.1.- Project goals

    The first iteration of the project will be deemed finished when it can do
    the following:

    1.- Run a minimal set of MIPS-I opcodes
        Excluding unaligned load/store (formerly patented).
        Excluding all CPA instructions.
        Excluding all CP0 instructions related to TLB.
        Cache instructions may or may not be implemented, I'll see.
    2.- Catch all undefined opcodes (and trigger exception).
    3.- Operate in kernel/user mode as per the architecture definition.
    4.- Handle exceptions in a manner compatible to MIPS-I standard.
    5.- Implement as much of CP0 as necessary for the above goals.
    6.- Be no bigger than Plasma in a Spartan-3 or Cyclone-2 device, and
        no slower -- Plasma is used as a reference in many ways.
        Speed measured in raw clock frequency for the time being.
        (I.e. don't not consider stalls, interlocks, etc. yet)
    7.- Interlock behavior of MUL/DIV and L* compatible to toolchain.
        That is, interlock loads instead of relying on a delay slot.

    Unaligned load/stores are excluded not because of patent concerns (the
    patents already expired) but because they're not essential for a first
    version of the core. The same goes for all other exclusions.


    For a second iteration I plan on the following:

    1.- Proper interlocking of load cycles (with no wasted cycles).
    2.- External interrupt support.
    3.- Code cache and data cache, even if not standard.
        No MMU and no TLB, and no cache-related instructions.
    4.- Interface to external SRAM (or FLASH) on 8- and 16-bit data bus.


    Many of the above goals have already been accomplished.



1.2.- Development status

    In its present state, the CPU can pass a basic opcode test and can execute
    some basic MIPS-I code compiled with standard gcc tools (specifically, it
    can run an 'Adventure' demo and a tiny 'hello world' program, see 
    section 6).
    'Basic' means that the core has a number of limitations that prevent it from
    running just any code -- mostly unimplemented instructions and skeletal
    memory interface.
    
    Besides, the core can already access external static memory (SRAM or FLASH)
    on 8-bit and/or 16 bit buses. 
    My main development target is a DE-1 board from Terasic (Cyclone-2) which
    happens to have that kind of memory on it.
    Wait states can be configured at synthesis, see section 2.6 below.
    Code sample 'memtest' takes advantage of this to do a basic test of the
    external SRAM, and code sample 'Adventure' uses both Flash and SRAM.
    

    The opcode test is included in '/src/opcodes/opcodes.s' (see section 6).


    This is the state of the CPU at this time:

    ### MIPS-I things not implemented
        - Kernel/user status.
        - RTE instruction -- as of now, returns from traps with JR.
        - Most of the CP0 registers and of course all of the CP1.
        - External interrupts.
        - Caches (there's an empty 'stub' cache and an unfinished real cache)

    ### Things implemented but not fully tested.
        - Memory pause input -- work in progress along with the cache module.

    ### Things with provisional implementation

        1.- Load interlocks: the pipeline is stalled for every load instruction,
            even if the target register is not used in the following
            instruction. So that every load takes two cycles.
            The interlock logic should check register indices and stall only if
            there is a data hazard.
            Note that all that's needed is a better identification of stall
            conditions; the logic to enable a load instruction that does not
            stall to overlap the next instruction is already in place.
            The interlock logic needs a stronger test bench anyway.
        2.- Documentation is too sparse and source code is barely commented.
            This is critical and I plan to fix it ASAP.


    ### Performance
    
    In my main test system, a Cyclone-2 grade -7, I'm quite sure that the core
    with caches and with mul/div and all other necessary functionality, plus 
    a barebones UART, will be below 2500 LEs, running at least at 50 MHz (with
    'balanced optimization' on Quartus-II).
    
    
    As soon as the core is in a stable state I will include a few synthesis
    performance numbers for common configurations.


1.3.- Next steps

    * Implement efficient load interlock detection with no wasted cycles.
    * Add a couple other code samples, including one with FP arithmetic.
    * Modify the software simulator so it can boot uClinux.
    * Make a uClinux port suitable for a R3000 derivative, from BuildRoot.





2.- CPU description
================================================================================


2.0.- Some general features

    * Synchronized to rising edge of clk only; no latches.
    * All inputs need to be synchronous to clk.
    * Synchronous register bank, both read and write ports.


2.1 Bus architecture

    The CPU uses a Harvard architecture: separate paths for code and data. It
    has three separate, independent buses: code read, data read and data write.

    The CPU will perform opcode fetches at the same time it does data reads
    or writes. This is not only faster than a Von Neumann architecture where
    all memory cycles have to be bottlenecked through a single bus; it is much
    simpler too. And most importantly, it matches the way the CPU will work
    when connected to code and data caches.

    (Actually, in the current state of the core, due to the inefficient way in
    which load interlocking has been implemented, the core is less efficient
    than that -- more on this later).

    The core can't read and write data at the same time; this is a fundamental 
    limitation of the core structure: doing both at the same time would take 
    one more read port in the register bank -- too expensive. Besides, it's not
    necessary given the 3-stage pipeline structure we use.

    In the most basic use scenario (no external memory and no caches), code and
    data buses have a common address space but different storages and the
    architecture is strictly Harvard. As soon as caches and external memory are
    implemented, the architecture will be Modified Harvard -- because data and 
    code will ultimately come from the same storage, on the same exetrnal 
    bus(es).

    Note that the basic cpu module (mips_cpu) is meant to be connected to 
    internal, synchronous BRAMs only. Some of its outputs are not registered
    because they needn't be. The final 'top' module will have its outputs
    registered as necessary to limit tco to acceptable values.


2.1.1 Code and data read bus interface

    Both buses have the same interface:

    *_rd_addr   : Address bus
    *_rd        : Data/opcode bus
    *_rd_vma    : Valid Memory Address (VMA)

    The CPU assumes SYNCHRONOUS external memory (most or all FPGA architectures
    have only synchronous RAM blocks):

    When *_rd_vma is active ('1'), *_rd_addr is a valid read address and the
    memory should provide read data at the next clock cycle.

    The following ascii-art waveforms depict simple data and code read cycles
    where there is no interlock -- interlock is discussed in section 2.3.


    ==== Chronogram 2.2.1.A: data read cycle, no stall ====================
                         ____      ____      ____      ____      ____
     clk            ____/    \____/    \____/    \____/    \____/    \____/

                         _________           _________
     data_rd_vma    ____/         \_________/         \____________________

     data_rd_addr   XXXX| 0x0700  |XXXXXXXXX| 0x0800  |XXXXXXXXX|XXXXXXXXX|

     data_rd        XXXX|XXXXXXXXX| [0x700] |XXXXXXXXX| [0x800] |XXXXXXXXX|

     (target reg)   ????|?????????|?????????| [0x700] |?????????| [0x800] |

              (data is registered here...)--^    (...and here)--^

     ==== Chronogram 2.1.1.B: code read cycle, no stall ===================
                         ____      ____      ____      ____      ____
     clk            ____/    \____/    \____/    \____/    \____/    \____/

                         __________________________________________________
    code_rd_vma     ____/         |         |         |         |         |

                    ????| 0x0100  | 0x0104  | 0x0108  | 0x010c  | 0x0200  |

    code_rd         XXXX|XXXXXXXXX| [0x100] | [0x104] | [0x108] | [0x10c] |

    p1_ir_reg       ????|?????????|?????????| [0x100] | [0x104] | [0x108] |

      (first code word is registered here)--^

    ========================================================================


    The data address bus is 32-bit wide; the lowest 2 bits are redundant since
    the CPU always reads full words, but they may be useful for debugging.

2.1.2 Data write interface

    The write bus does not have a vma output because byte_we fulfills the same
    role:

    *_wr_addr   : Address bus
    *_wr        : Data/opcode bus
    byte_we     : WE for each of the four bytes

    Write cycles are synchronous too. The four bytes in the word should be
    handled separately -- the CPU will assert a combination of byte_we bits
    according to the size and alignment of the store.

    When byte_we(i) is active, the matching byte at data_wr should be stored
    at address data_wr_addr. byte_we(0) is for the LSB, byte_we(3) for the MSB.
    Note that since the CPU is big endian, the MSB has the lowest address and
    LSB the highest. The memory system does not need to care about that.

    Write cycles span a single clock cycle and never cause data-hazard stalls.

    This is the waveform for a basic write cycle.

    ==== Chronogram 2.1.2: data write cycle ===============================
                         ____      ____      ____      ____      ____
     clk            ____/    \____/    \____/    \____/    \____/    \____/

     byte_we        XXXX|  1111   |  0000   |  0100   |  1100   |  0000   |

     data_wr_addr   XXXX| 0x0700  |XXXXXXXXX| 0x0800  | 0x0900  |XXXXXXXXX|

     data_wr        XXXX|12345678h|XXXXXXXXX|12345678h|12345678h|XXXXXXXXX|

     [0x0700]       ????|????????h|12345678h|12345678h|12345678h|12345678h|

     [0x0800]       ????|????????h|????????h|????????h|??34????h|??34????h|

     [0x0900]       ????|????????h|????????h|????????h|????????h|1234????h|

    ========================================================================

    Note the two back-to-back stores to addresses 0x0800 and 0x0900. They are
    produced by two consecutive S* instructions (SB and SH in the example),
    and can only be done this fast because of the Harvard architecture.


2.1.3 Memory wait cycles

    Memory wait cycles have already been implemented and tested with a 'stub'
    cache (module mips_cache_stub) and the first version of the real cache
    (module mips_cache.vhdl). The 'stub cache' is actually just an interface
    to external 8/16-bit wide memory that has only been barely tested on real 
    hardware. This stub cache is described in section 2.7 below while the real
    cache is descibed in section 2.8.
    The memory wait state logic is a work in progress and might change as 
    development on the cache module proceeds.

    In short, the 'mem_wait' input will unconditionally stall all pipeline
    stages as long as it is active. It is meant to be used by the cache at cache 
    refills.

    Again, the current implementation of the wait input and its logic is going
    to change. Eventually it will be described here.

    


2.2 Pipeline

    Here is where I would explain the structure of the cpu in detail; these 
    brief comments will have to wait until I write some real documentation.
    
    This section could really use a diagram; since it can take me days to draw 
    one, that will have to wait for a further revision.
    
    This core has a 3-stage pipeline quite different from the original 
    architecture spec. Instead of trying to use the original names for the
    stages, I'll define my own.
    
    A computational instruction of the I- or R- type goes through the following
    stages during execution:
    
        * FETCH-0   : Instruction address is in code_rd_addr bus
        * FETCH-1   : Instruction opcode is in code_rd bus
        * ALU/MEM   : ALU operation or memory read/write cycle is done OR
                      Memory read/data address is on data_rd/wr_address bus OR
                      Memory write data is on data_wr bus
        * LOAD      : Memory read data is on data_rd bus
        
    In the core source (mips_cpu.vhdl) the stages have been numbered:
    
        FETCH-1 = stage 0
        ALU/MEM = stage 1
        LOAD    = stage 2
    
    Here's a couple of examples:
    

    ==== Chronogram 2.2.A: stages for instruction "lui gp,0x1" ============
                         ____      ____      ____      ____      ____
     clk            ____/    \____/    \____/    \____/    \____/    \____/

     code_rd_addr       | 0x099c  |                                        
     
     code_rd_data                 |3c1c0001h|

     rbank[$gp]                             | 0x0001  |
     
                        |< fetch0>|<   0   >|<   1   >|
                        
    ==== Chronogram 2.2.B: stages for instruction "lw a0,16(v0)" ==========
                         ____      ____      ____      ____      ____
     clk            ____/    \____/    \____/    \____/    \____/    \____/

     code_rd_addr       | 0x099c  |                                        
     
     code_rd_data                 |8c420010h|
     
     data_rd_addr                           | $v0+16  |
                                             _________
     data_rd_vma                       _____/         \______
     
     data_rd                                          | <data>  |

     rbank[$a0]                                                 | <data>  |
     
                        |< fetch1>|<   0   >|<   1   >|<   2   >|
                        
    ========================================================================
  
    (Both instructions at address 0x099c)
  
    
    In the source code, all registers and signals in stage <i> are prefixed by 
    "p<i>_", as in p0_*, p1_* and p2_*. A stage includes a set of registers and 
    all the logic that feeds from those registers (actually, all the logic
    that is between registers p0_* and p1_* belongs in stage 0, and so on).
    Since there are signals that feed from more than one pipeline stage (for
    example p2_wback_mux_sel, which controls the register bank write port data 
    multiplexor and feeds from p1 and p2), the naming convention has to be
    a little flexible.
    
    FETCH-0 would only include the logic between p0_pc_reg and the code ram 
    address port, so it has been omitted from the naming convention.
    
    All read and write ports of the register bank are synchronous. The read 
    ports belong logically to stage 1 and the write port to stage 2.
    
    IMPORTANT: though the register bank read port is synchronous, its data can
    be used in stage 1 because it is read early (the read port is loaded at the 
    same time as the instruction opcode). That is, a small part of the 
    instruction decoding is done on stage FETCH-1. Bearing in mind that the code 
    ram is meant to be the exact same type of block as the register bank (or 
    faster if the register bank is implemented with distributed RAM), and we 
    will cram the whole ALU delay plus the reg bank delay in stage 1, it does 
    not hurt moving a tiny part of the decoding to the previous cycle.
    
    All registers but a few exceptions belong squarely to one of the pipeline
    stages:
    
    
    Stage 0:
    p0_pc_reg                               : PC
    <external code ram read port register>  : Loads the same as PC
    
    Stage 1:
    p1_ir_reg                               : Instruction register
    <register bank read port register>      :
    p1_rbank_forward                        : Feed-forward data (hazards)
    p1_rbank_rs_hazard                      : Rs hazard detected
    p1_rbank_rt_hazard                      : Rt hazard detected
    
    Stage 2:
    p2_exception                            : Exception control (not finished)
    p2_do_load                              : Load from data_rd
    p2_ld_*                                 : Load control
    <register bank write port register>     :
    
    Note how the register bank ports belong in different stages even if it's
    the same physical device. No conflict here, hazards are handled properly
    (logic defined with explicit vhdl code, not with synthesis pragmas, etc.).
    
    
    There is a small number of global registers that don't belong to any 
    pipeline stage:
    
    pipeline_stalled                        : Together, these two signals...
    pipeline_interlocked                    : ...control pipeline stalls
    
    
    And of course there are special registers accessible to the code:
    
        mdiv_hi_reg     : register HI from multiplier block
        mdiv_lo_reg     : register LO from multiplier block
        cp0_status      : register CP0[status]
        cp0_epc         : register CP0[epc]
        cp0_cause       : register CP0[cause]
        
    These belong logically to pipeline stage 1 (can be considered an extension
    of the register bank) but have been spared the prefix for clarity.

    Note that the CP0 status and cause registers are only partially implemented.

    Again, this needs a better explaination and a diagram.


2.3 Interlocking and data hazards

    There are two data hazards we need to care about:
    
    a) If an instruction needs to access a register which was modified by the
    previous instruction, we have a data hazard -- because the register bank is
    synchronous, a memory location can't be read in the same cycle it is updated
    -- we will get the pre-update value.
    
    b) A memory load into a register Rd produces its result a cycle late, so if
    the instruction after the load needs to access Rd there is a conflict.


    Conflict (a) is solved with some data forwarding logic: if we detect the
    data hazard, the register bank uses a 'feed-forward' value instead of the
    value read from the memory file. 
    In file mips_cpu.vhdl, see process 'data_forward_register' and the following
    few lines, where the hazard detection logic and data register and 
    multiplexors are implemented. Note that hazard is detected separately for
    both read ports of the reg bank (p0_rbank_rs_hazard and p0_rbank_rt_hazard).
    Note that this logic is strictly regular vhdl code -- no need to rely here
    on the synthesis tool to add the bypass logic for us. This gets us some
    measure of vendor independence.
    
    As for conflict (b), in the original MIPS-I architecture it was the job
    of the programmer to make sure that a loaded value was not used before it
    was available -- by inserting NOPs after the load instruction, if necessary.
    This is what I call the 'load delay slot', as discussed in [2], pag. 13-1.
    
    The C toolchain needs to be set up for MIPS-I compliance in order to build
    object code compatible with this scheme.
    But all succeeding versions of the MIPS architecture, including the MIPS-32
    that this core aims to be compatible with in the future, implement a 
    different scheme instead, 'load interlock' ([1], pag. 28).
    In short, it pays to implement load interlocks so this core does, but the
    feature should be optional through a generic.
    
    
    Load interlock is triggered in stage 1 (ALU/MEM) of the load instruction;
    when triggered, the pipeline stages 0 and 1 stall, but the pipeline stage
    2 is allowed to proceed. That is, PC and IR are frozen but the value loaded
    from memory is written in the register bank.
    
    In the current implementation, the instruction following the load is 
    UNCONDITIONALLY stalled; even if it does not use the target register of the 
    load. This prevents, for example, interleaving read and write memory cycles
    back to back, which the CPU otherwise could do.
    So the interlock should only be triggered when necessary; this has to be
    fixed.


    ==== Chronogram 2.3.A: data read cycle, showing interlock =============
                         ____      ____      ____      ____      ____
     clk            ____/    \____/    \____/    \____/    \____/    \____/

     code_rd_addr   XXXX| 0x099c  | 0x09a0            | 0x09a4  | 0x09a8  |
     
     byte_we        XXXX|  0000   |  1111   |  0000   |  0000   |  1100   |
     
                                            |<                 >|
                    ________________________           ____________________
     code_rd_vma                            \_________/               
                                             _________                    
     data_rd_vma    ________________________/         \____________________

     data_rd_addr   XXXX|XXXXXXXXX|XXXXXXXXX| 0x0700            |XXXXXXXXX|

     data_rd        XXXX|XXXXXXXXX|XXXXXXXXX|XXXXXXXXX| [0x700] |XXXXXXXXX|

     (target reg)   ????|?????????|?????????|?????????| [0x700] |?????????|

                           (data is registered here)--^

    ========================================================================

    Note how a fetch cycle is delayed.

    This waveform was produced by this code:
    
                ...
                998:    ac430010    sw  v1,16(v0)
                99c:    80440010    lb  a0,16(v0)
                9a0:    a2840000    sb  a0,0(s4)
                9a4:    80440011    lb  a0,17(v0)
                9a8:    00000000    nop
                ...

    Note how read and write cycles are spaced instead of being interleaved, as
    they would if interlocking was implemented efficiently (in this example, 
    there was a real hazard, register $a0, but that's coincidence -- I need to
    find a better example in the listing files...).


2.4 Exceptions

    The only exceptions supported so far are software exceptions, and of those 
    only the instructions BREAK and SYSCALL and the unimplemented opcode trap.
    
    Both do a limited version of the regular MIPS exception behavior.
    They save their own address to EPC, abort the following instruction, and
    jump to the exception vector 0x03c. All as per the specs except the vector
    address.
        
    The following instruction is aborted even if it is a load or a jump, and 
    traps work as specified even from a delay slot -- in that case, the address
    saved to EPF is not the victim instruction's but the preceding jump 
    instruction's as explained in [1], pag. 64.
    
    Plasma used to save in epc the address of the instruction after break or 
    syscall. This core will use the standard MIPS way instead.
    
    Note that the epc register is not used by any instruction other than mfc0;
    ERET is not implemented yet, because privilege levels aren't either.


2.5.- Multiplier

    As of revision 18, the core already includes a multiplier module.
    
    It uses a slightly modified version of Plasma's multiplier unit. Changes
    have been commented in the source code. 
    
    The main difference is the Plasma does not stall the pipeline while a 
    multiplication/division is going on. It only does when you attempt to get 
    registers HI or LO while the multiplier is still running. Only then will
    the pipeline stall until the operation completes.
    This core instead stalls always for all the time it takes to do the 
    operation. Not only it is simpler this way, it will also be easier to 
    abort mult/div instructions.
    
    The logic dealing with mul/div stalls is a bit convoluted and coud use some
    explaining and some ascii chronogram. Again, TBD.


2.6.- Memory map definition

    The system memory map is hardcoded in function 'decode_address_mips1', 
    defined in package 'mips_pkg.vhdl'.

    The MIPS architecture specs define a memory map which determines which areas
    are cached and which is the default address translation ([2], page 2-8).
    
    The core as of now does not support any kind of memory translation: program 
    addresses are always identical to hardware addresses.
    The memory map attributes are only relevant to the cache module; the cache 
    is the only module responsible for accessing external storage; it needs to 
    know how to do it. for each address, the cache needs to know:
    
        a.- What kind of memory it is
        b.- How many wait states to use
        c.- Whether it is readable or not
        d.- Whether it is cacheable or not
        
    In the present implementation the memory map can't be modified at run time.
    
    The cache module uses 'decode_address_mips1' to determine what to do for 
    each cache refill -- the refill state mechine is different for each kind of 
    memory, see section 2.7. 
    
    Note that the cache stub implements only points a, b and c.


2.7.- 'Stub' cache

    As of revision 53, there is a first synthesizable version of the cache, a 
    'stub' with almost no functionality meant to bring the system up.
    The cache in its present state (rev. 53) is just an interface to external
    static RAM and internal FPGA block RAM as read-only, plus some minimal
    support for I/O (used to access the UART).
    It is functionally equivalent to a 1-word data and code cache which always 
    misses. It is only good for interfacing the CPU to external memory, it does
    not provide any performance gain.
    
    Line size is 1 word for both data and code. That is, all refills are for
    one single word.
    
    
2.7.1.- Stub cache refill timing diagrams
    
    
    For each type of memory supported by the cache there is a refill state 
    machine (i.e. a path within the cache state machine). Rather than drawing 
    the state machine diagram I will draw the memory access chronograms for
    each kind of memory.
    
    I expect that much of what I will write here is readily apparent by 
    examining the state machine transition logic, I hope this will help clarify
    everything.
    
    *** Block RAM **********************************************************
    
    Block RAM (internal synchronous FPGA RAM) is only supported for code read
    accesses of 32-bit words. The type of memory is meant for startup code and
    small debug applications so speed is not important.
    

    ==== Chronogram 2.7.1.A: code refill from block RAM ====================
    
                       __    __    __    __    __    __    __    __    __
     clk            __/  \__/  \__/  \__/  \__/  \__/  \__/  \__/  \__/  \_

     code_rd_addr   XX| 0x099c                      | 0x09a0            ...
     
                            |<    stalled          >|     |< stalled ...>
                       _____                         _____
     code_rd_vma    __/     \_______________________/     \________________

     cache/ps       XX|idle       |[1]  |[2]  |[3]  |idle       |[1]  |[2]  |[3] 
                             _____                         _____
     code_miss      ________/     \_______________________/     \__________
     
                    __       _______________________       ________________
     cpu_mem_wait     \_____/                       \_____/


     bram_rd_addr     XXXXXXXXXXXX| 0x009c                      | 0x009a
    
     bram_rd_data     XXXXXXXXXXXXXXXXXX| 0x12345678                   |...

    ========================================================================

    The diagram shows two such code refills back to back. The BRAM address in
    this example is just the low 8 bits of the full address.

    In the diagram, 'ps' is the 'present state' register of the cache state 
    machine, and the states are labeled as this:
    
        [1] = code_refill_bram_0
        [2] = code_refill_bram_1
        [3] = code_refill_bram_2
        
    As you see we're in no hurry... 5 cycles to read a word from a 32-bit wide 
    BRAM is a lot, but this is what we pay for not using a dedicated data path 
    for each kind of memory.
    
    
    *** Static 16-bit memory (SRAM in the DE-1 board) **********************
    
    This is a BRAM refill (like the one pictured above) followed by a static
    refill with 1 wait state:
    
    
    ==== Chronogram 2.7.1.B: code refill from static 16-bit memory =========

                      _   _   _   _   _   _   _   _   _   _   _   _   _   _
     clk            _/ \_/ \_/ \_/ \_/ \_/ \_/ \_/ \_/ \_/ \_/ \_/ \_/ \_/ \

     code_rd_addr   X| 0x0004            | 0x0008                | 0x000c
                         |<    stalled  >|   |< stalled         >|
                      ___                 ___                     ___
     code_rd_vma    _/   \_______________/   \___________________/     ...

     cache/ps       X|idle   | 1 | 2 | 3 |idle   | 5     | 6     |
                    _     _______________     ___________________
     cpu-mem_wait    \___/               \___/                   \___  ...
                          ___                 ___
     code_miss      _____/   \_______________/   \___________________  ...
                                              ___     ___
     load_ws_ctr    _________________________/   \___/   \___________  ...
     
     ws_value       XXXXXXXXXXXXXXXXXXXXXXXXX| 1 |XXX| 1 |XXXXXXXXXXX  ...
     
     ws_ctr             0                        | 1 | 0 | 1 | 0       ...

     sram_addr      XXXXXXXXXXXXXXXXXXXXXXXXXXXXX| 0x021 | 0x023 |XXX  ...
    
     sram_data_rd   -----------------------------< 0x1234| 0x5678>---  ...
                    _____________________________                 __
     sram_oe_n                                   \_______________/     ...

    ========================================================================
    
    Bus sram_addr is the address bus pyhsically connected to external static
    memories, both 16-bit and 8-bit wide. 16-bit devices are not connected to
    sram_addr(0); that bit is left at '1' on 16-bit accesses and we can ignore
    it in this example.
    
    You can see that the target 32-bit word at address 0x08 is read over two
    consecutive memory cycles of two clock cycles each (one of which is a wait
    state). The code word is read MSB half first, in this example the code
    word is 0x012345678.
    
    Since each 32-bit word takes up 2 16-bit words, the target word is at SRAM 
    location 0x08*2=0x010, which becomes 0x020 when we take bit sram_addr(0)
    into account. 
    
    This explains the values 0x021 and 0x023 for sram_addr. I hope this 
    explaination made sense...
    
    The states are labelled like this:
    
        [1] = code_refill_bram_0
        [2] = code_refill_bram_1
        [3] = code_refill_bram_2
        [4] = code_refill_sram_0
        [5] = code_refill_sram_1
    
    Signals ws_ctr, ws_value and load_ws_ctr are all related to the wait state
    counter (ws_ctr). 
    
    A number of cases are still to be documented:
    
        Code refill from 8-bit static memory.
        Data refill from 16-bit static memory.
        Data refill from 8-bit static memory.
        Data refill from 32-bit sync IO memory.
        Data refill from 32-bit BRAM memory.
    
    They are all easy to figure by reading the source but I will add a diagram 
    as soon as possible.
    

2.7.2.- Stub cache writethrough timing diagrams
    
    The stub bache only supports writes to static 16-bit RAM and synchronous
    32-bit IO ports.
    
    The following diagram shows a code refill from 16-bit SRAM followed by a 
    writethrough to 16-bit SRAM.
    Note that the code refill always happens before any other cache operation.
    And note that the code word being read is NOT the write instruction but
    the one after it.
    
    
    ==== Chronogram 2.7.2.A: writethrough to static 16-bit memory ==========

                      _   _   _   _   _   _   _   _   _   _   _   _   _   _
     clk            _/ \_/ \_/ \_/ \_/ \_/ \_/ \_/ \_/ \_/ \_/ \_/ \_/ \_/ \

     code_rd_addr   X| 0x0008                                        | 0x000c
                         |<    stalled                              >|
                      ___                                             ___
     code_rd_vma    _/   \___________________________________________/   \

     cache/ps       X|idle   | 5     | 6     | 7 | 8 | 9 | A | B | C |idle
                    _     ___________________________________________
     cpu-mem_wait    \___/                                           \___/
                          ___     ___
     load_ws_ctr    _____/   \___/   \___________________________________
     
     ws_ctr          0       | 1 | 0 | 1 | 0       

     sram_addr      XXXXXXXXX| 0x021 | 0x023 | 0xff5     | 0xff7     |XXXX
    
     sram_data_rd   ---------< 0x1234| 0x5678>----------------------------
     
     sram_data_wr   -------------------------< 0xabcd    | 0xef01    >----
                    _________                 ____________________________
     sram_oe_n               \_______________/     
                       __________________________     _______     ________
     sram_byte_we_n(1)                           \___/       \___/
                       __________________________     _______     ________
     sram_byte_we_n(0)                           \___/       \___/

    ========================================================================
    
    State labels:
    
        [5] = code_refill_sram_0
        [6] = code_refill_sram_1
        [7] = data_writethrough_sram_0a
        [8] = data_writethrough_sram_0b
        [9] = data_writethrough_sram_0c
        [A] = data_writethrough_sram_1a
        [B] = data_writethrough_sram_1b
        [C] = data_writethrough_sram_1c
    
    In order to guarantee the address and data setup and hold times we have 
    to use 3 clock cycles per write cycle. This is very slow but there is no way
    around it if we want a fully synchronous design. Unlike the refill, which
    has 1 wait state, the writethrough doesn't need any -- for the chips on the
    DE-1 board. Wait states are configured in the package mips_pkg.
    
    Note this architecture always writes whole words (because SWR, SWL are 
    unimplemented) so the byte enables are always asserted together.


    ==== Chronogram 2.7.2.B: writethrough to synchronous 32-bit IO =========

                      _   _   _   _   _   _   _   _   _   _   _   _   _   _
     clk            _/ \_/ \_/ \_/ \_/ \_/ \_/ \_/ \_/ \_/ \_/ \_/ \_/ \_/ \

     code_rd_addr   X| 0x0004            | 0x0008            | 0x000c
                         |<    stalled  >|   |< stalled     >|   
                      ___                 ___                 ___
     code_rd_vma    _/   \_______________/   \_______________/   \_________

     cache/ps       X|idle   | 1 | 2 | 3 | D | i | 1 | 2 | 3 |idle   | ...
                    _     _______________     _______________     ____
     cpu-mem_wait    \___/               \___/               \___/     ...
                          ___                 ___                 ___
     code_miss      _____/   \_______________/   \_______________/   \ ...

     io_byte_we      0                   |f  | 0                       ...

    ========================================================================

    State labels:

        [i] = idle
        [1] = code_refill_bram_0
        [2] = code_refill_bram_1
        [3] = code_refill_bram_2
        [D] = data_write_io_0

    IO ports are not meant to be cached and will not be in the final version of
    the cache. But the writethrough needs to be implemented in the state 
    machine at any rate.
    Note that the IO byte we signals are all asserted at once in the current 
    implementation of the core (because no half-word or unaligned stores are
    supported).



2.8.- Cache module ('real' cache as opposed to the 'stub' above)

    As of revision 114, the project already includes a real cache module, still
    unfinished. Both the simulation template and the synthesis template still
    use the stub cache by default, so if you want to test the real cache you 
    have to modify the templated manually.
    
    Only the I-Cache is implemented; the D-Cache still uses the stub logic from
    the mips_cache_stub module. Besides, SDRAM is not supported yet. And there
    are a number of loose ends in the implementation still to be solved. For
    example, the cache size is supposed to be parametrizable through generics; 
    but though the generics are already there, the actual code does not use them
    and uses hardcoded constants instead. There's many things like this
    still unfinished.
    
    As time permits I will add timing diagrams to this section. For now, I will
    only say that the timing diagrams will be nearly identical to those of the
    stub cache with only one important difference: In the stub cache, each 
    refill operation only reads a single word from memory, whereas in the real 
    cache each refill reads 4 words in reverse order (i.e. 3, 2, 1, 0 LSB 
    address bits).


2.8.1.- Cache initialization and control

    Bits 17 and 16 of the SR are NOT used for their standard MIPS-I purpose.
    Instead they are used as explained below:
    
    - Bit 17: Cache enable              [reset value = 0]
    
        When '0', caches are disables. All memory accesses will trigger a 
        cache refill (even sucessive accesses to the same line).
        When '1', caches are enabled and work as usual.
    
    - Bit 16: I-Cache line invalidate   [reset value = 0]
    
        When bits 17:16='01', writing word X.X.X.N to ANY address will 
        invalidate I-Cache line N (N is an 8-bit word and X is an 8-bit 
        don't care).
        Besides, the actual write will be performed too.
        When bit 16 is '0', the cache will work as usual.
        When bits 17:16='11' cache behavior is UNDETERMINED.

    Now, after reset the cache memory comes up in an undetermined state but 
    it comes up disabled too. Before enabling it, you need to invalidate all
    cache lines in software (see routine cache_init in the memtest sample).
    
    Note that there are no 'uncached' memory areas in the current version of
    the core; all memory addresses are cacheable unless they are defined as
    IO (see mips_cache.vhdl). 


2.8.2.- Cache tags, cache address mirroring and uncacheable blocks

    FIXME This is explained in the cache source; should be explained here too



3.- Logic simulation
================================================================================

    The project has been simulated using Modelsim 6.3g. The test bench
    uses some features not present in earlier versions so if you use some other
    simulator or some earlier version of Modelsim, see section 3.3 below.

    In short, the simulation test bench is meant to run any of the code samples
    provided in directory /src, under a controlled environment, while logging
    the cpu state to a text log file.

    This log file can then be compared to a log file generated by a software
    simulator for the same code sample (see section 5.1). The software
    simulator is the 'golden model' against which the cpu is tested, so any
    difference between both log files means trouble.

    This method is far easier than building a fully automated test bench, and
    much more convenient and reliable than a visual inspection of the simulation
    state.

    There are a few simulation test bench templates in the /src directory, which 
    are used by all the code samples (and there's just two code samples in this 
    release of the project...). 
    The only one actually useful is '/src/mips_tb2_template.vhdl'. The others
    are remnants of previous versions that will be removed ASAP.
    
    The template in file '/src/mips_tb2_template.vhdl' is filled in with all 
    the necesary data (mostly memory init. strings) from the
    code sample object file(s) and then written to '/vhdl/tb/mips_tb2.vhdl'.
    The idea is that these tb templates are an execution harness to be shared by 
    all test programs. See the template comments for a quick explaination of
    their purpose (and the reason there is more than one template).

    The test bench templates provided are only good to test instruction
    execution and basic core functionality. As the project moves forward and
    new features are added (e.g. caches) I will add more test bench templates.


3.1.- Running the simulation

    A simulation script can be found at '/sim/mips_tb2.do'. This script will
    simulate test bench file '/vhdl/tb/mips_tb2.vhdl'. 
    The idea is that script 'mips_tb<i>.do' will run file 
    '/vhdl/tb/mips_tb<i>.vhdl', though there's only one right now -- please 
    see the source sample makefiles.
    
    As of revision 70 and above, you should use mips_tb2 for all code samples.

    The test bench file is automatically generated for each of the sample
    programs (because it contains initialized memories with the program object
    code, etc.). This is automatically done by the sample code makefile,
    assuming you have a MIPS cross-toolchain in your computer (see section 6).

    For convenience, a pre-generated mips_tb2.vhdl is included so you can launch
    a simulation without having to install toolchains, etc. The code is that
    of the 'hello world' sample.

    I guess that if you are interested in this sort of stuff then you probably
    know more about Modelsim than I do. Yet, here's a step-by-step guide to
    simulating the 'hello world' sample:

    1.- Run 'make hello_sim' from directory '/src/hello'.
        This will compile the program sources, build the necessary binary object
        files and then create a vhdl simulation test bench with memories
        initialized with the object code. The simulation test bench is created
        as '/vhdl/tb/sim_tb2.vhdl'. You can change that by editing the makefile.
        Read the makefile and comments in the python script '/src/bin2hdl.py'
        for details.

        ALTERNATIVELY, if you don't have a toolchain you can just skip this
        step and use the default 'mips_tb2.vhdl' file provided.

    2.- In modelsim, change directory to /syn (menu file->change directory)
        Modelsim will create its stuff in this directory. This includes the
        log file, which by default will be '/syn/hw_sim_log.txt'.
        (You could use any other directory, this is just a convenient place to
        put modelsim data out of the way. Just remember where the log file is.).

    3.- Run script '/sim/mips_tb2.do' (menu tools->tcl->execute macro)
        The simulation will run to completion. In Modelsim's transcript window
        you will see the program console output, in this case a 'hello world'
        message.
        NOTE: Other versions of modelsim have slightly different menus.

    That's it, really.

    Be aware that the simulation timeout is arbitrarily fixed in the makefile. 
    This time may or may not be enough to execute the program. Change it if
    necessary.
    I should include some means to check for program termination (perhaps a
    debug register written to from boot.s after returning from main, or vhdl
    debug code that catches 1-instruction closed loops).



3.2.- Simulation file logging

    The test bench will log any of the following events:

    - Changes in the register bank.
    - Changes in registers HI and LO (implemented even if mul/div is not).
    - Changes in register EPC (implemented even though it is unused).
    - Data loads (any resulting register change is logged separately).
    - Data stores.

    Note that changes in other internal registers, including PC, are not logged.
    This means that for example a long chain of NOPs, or MOVEs that don't change
    register values, will not be seen in the log file.

    Events are logged with the current value of the PC; this value usually
    points to the instruction following the instruction that triggered the
    event, due to pipelining. This holds true even for load instructions.

    The simulation log file is stored by default in modelsim's working directory
    (see above). I don't provide any automated script to do the comparison, you
    should use whatever diff tool you like best.


3.2.1.- Log file format

    There is a text line for each of the following events:

    * Register change

        "(pc) [reg_num]=value"

        Where:

        pc      => PC value (8-digit hex)
        reg_num => Register index (2-digit hex), or any of {LO,HI,EP}
        value   => New register value (8-digit hex)

    * Write cycle (store)

        "(pc) [address] |mask|=value WR"

        Where:

        pc      => PC value (8-digit hex)
        address => Write address
        mask    => Byte-enable mask (2-digit hex)
        value   => Write data

        The PC value is the address of the instruction that caused the logged
        change, NOT the actual value of the PC at the time of the change. 
        This is so to make the hardware logger's life easier -- the SW simulator
        and the real HW don't work exactly the same when the cache starts 
        stalling the cpu (which the SW does not simulate) and the best reference
        point for all instructions is their own adddress.

        The mask will have a '1' at bits 3..0 for each byte write-enabled. MSB
        is bit 3, LSB is bit 0. Note that the data is big endian, so the MSB
        is actually the LOWER address. The upper nibble of the mask is always 0.

        The value will match the behavior of the ion cpu; the significant
        byte(s) will have the actual write data and the other bytes will not
        be relevant but will behave exactly as the real hardware (so that the
        logs are directly comparable).

        The WR at the end of the line is for visual reference only.

    * Read cycle (load)

        "(pc) [address] <**>=value RD"

        Where:

        pc      => PC value (8-digit hex)
        address => Read address
        <**>    => Padding (ignore)
        value   => Read data

        Note that in the real machine, the data is read into the cpu one cycle
        after the address bus is output (because the memory is synchronous) so
        that the full read cycle spans 2 clock cycles (when proper interlocking
        is implemented, the load will overlap the next instruction; right now
        it just stall the pipeline for 1 cycle). This is simplified in the log
        files for readability.

        Note that the size of the read (LH/LB/LW) instruction is not recorded.

        The RD at the end of the line is for visual reference only.


    For example, these are lines 274-281 of the simulation log for the
    default 'hello world' test bench:

                ...
                (00000230) [04]=00010000
                (00000234) [1D]=00010230
                (00000238) [00010244] |0F|=00000038 WR
                (0000023C) [1F]=00000240
                (00000288) [00010000] <**>=636F6D70 RD
                (00000288) [05]=00000063
                (00000294) [07]=0000000A
                (00000298) [03]=20000000
                ...

    (NOTE: this example taken from revision 1, yours may vary)

    The read cycle at pc=0x288 modifies register 0x05; that's why there are two
    lines with the same pc value.

    The code that produced that log is this (from hello.lst):

                ...
                22c:    3c040001    lui a0,0x1
                230:    27bdffe8    addiu   sp,sp,-24
                234:    afbf0014    sw  ra,20(sp)
                238:    0c0000a1    jal 0x284
                23c:    24840000    addiu   a0,a0,0
                ...
                284:    90850000    lbu a1,0(a0)
                288:    00000000    nop
                ...

    (Remember the register numbers: $a0=4, $sp=1d and $ra=1f)

    Please note the addiu instruction in the jal delay slot (which is
    effectively a nop)and how all changes are logged with the 'next' pc value:
    the jal change to register 0x1f is logged at the jump target address, and
    not at the delay slot address.
    I hope this is not too confusing. It'd be great if we could see the log for
    a delay-slot instruction other than nop, I'll have to fetch an example from
    the listing...


    The log file format is hardcoded into vhdl package mips_sim_pkg
    and the software simulator C source that implement it. It will
    be probably modified as the project moves on.

    Note that the software simulation log and the modelsim log need not be the
    same size; the one that spans a longer simulated time will be longer.
    The point is that both need to be identical up to the last line of the
    shortest file.



3.3.- Use of Modelsim features

    Apart from the format of the simulation scripts, which would be easy to port
    to any other simulation tool, the simulation test bench uses a feature of
    Modelsim 6.3 that is not even present in earlier versions -- SignalSpy.

    The test bench uses SignalSpy to examine internal cpu signals from the top
    entity, including the whole register bank. There is no other way to examine
    those signals in vhdl, unless you want to add them to the module interface.

    The test bench needs to access those signals in order to detect changes in
    the internal cpu state that should be logged. That is, it really needs to
    look at those signals if it is to be of any use.

    If you are using any other simulation tool, look for an alternative method
    to get those internal signals or just add them to the core interface. I
    would suggest adding a debug port of type record to mips_cpu -- and hope the
    synthesis tool does not choke on it. Adding individual debug ports would be
    a PITA. 
    I guess this is why Mentor people took the trouble to write SygnalSpy.

    I plan to move to Symphony EDA eventually, so I'll have to fix this.



4.- Hardware demo
================================================================================


4.1.- Pre-generated demo

    The project includes 3 synthesizable code samples, a 'Hello world' demo
    and a memory tester. Only the 'hello' demo is included in pre-generated 
    form, the others have to be built using the included makefiles.

    This is just for convenience, so that you can launch some demo on hardware
    without installing the C toolchain.
    
    A constraints file is provided ('/vhdl/demo/c2sb_demo.csv') which includes
    all the pin constraints for the default target board, in CSV format. This
    constraints file is shared by all demos targeted to the DE-1 board.

    This demo has only been tested on a single dev board: terasIC's DE-1,
    with a Cyclone-II FPGA (EP2C20F484C7).

    I have used the free Altera IDE (Altera Quartus II 9.0). This version of
    Quartus does not even require a free license file and can be downloaded for
    free from the altera web site. But if you have a DE-1 board on hand I guess
    you already know that.

    I assume you are familiar with Altera tools but anyway this is how to set up
    a project using Quartus II:

        1.- Create new project with the new project wizard
            Top entity should be c2sb_demo
            Suggested path is /syn/altera/<project name>
        2.- Set target device as EP2C20F484C7
            This choice determines speed grade and chip package
        3.- 'Next' your way out of the new project wizard
        4.- Add to the project all the vhdl files in /vhdl and /vhdl/demo
            Select file c2sb_demo.vhdl as top
        5.- Import pin constraints file (assignments->import assignments)
        6.- Create a clock constraint for signal clk (52 MHz or some other
            suitable speed which gives us some minimal slack).
        7.- In the device settings window, click "Device and pin options..."
        8.- Select tab "Dual-Purpose pins"
        9.- Double-click on nCEO value column and select "use as regular I/O"
            IMPORTANT: otherwise the synthesis will fail; we need to use a FPGA
            pin that happens to be dual-purpose (programming and regular).
        10.-Save the project and synthesize
        11.-Make sure the clock constraint is met (timing analyzer report)
        12.-If you have a terminal hooked to the serial port (19200/8/N/1) you
            should see a welcome message after depressing the reset button.

    In case you need to troubleshoot, my synthesis of the default demo is
    usually like this:

        - Selected optimization: balanced
        - All other options: default
        - <2250 LEs plus 27 M4K blocks if you use the real cache
        - Clock constraint met but not by much (~53 MHz)
        - <60 warnings, mostly harmless (ugliest: unused pins, undeclared clock)

    Note that none of the on-board goodies are used in the demo except as noted
    in section 4.2 below.

    In order to generate the demos (not using the pre-generated file) you
    have to use the makefiles provided with the code samples. Please see 
    the sample readme files and the makefiles for details. In short, provided
    you have a MIPS toolchain installed and Python 2.5, all you have to do
    is run make (which will automatically build all the vhdl files where they
    need to be, etc.) and run the synthesis.
    


4.2.- Porting to other dev boards

    I will only deal here with the 'hello' demo.

    The 'hello' demo should be easily portable to any board which has all of 
    this:

        - An FPGA capable enough (the demo uses internal memory only)
        - A reset pin (possibly a pushbutton)
        - A clock input (uart modules assume 50MHz, see below)
        - RXD and TXD UART pins, plus a connector, header or whatever

    The only modules that care at all about clock rate are the UART
    modules. They are hardwired to 19200 bauds when clocked at 50MHz, so if you
    use a different frequency you must edit the constants in the uart files
    accordingly.
    Be aware that these uart modules have been used in other projects but have
    seldom been tested with other than 50MHz clocks; they should work but you
    have been warned.

    Though there is no reset control logic, the reset input is synchronized 
    internally, so you can use a raw pushbutton -- you may trigger multiple 
    resets if your pushbutton isn't tight but you'll never cause metastability 
    trouble.

    Assuming you take care of all of the above, the easiest way I see to port
    the demo is just editing the top module ports ('/vhdl/demo/c2sb_demo.vhdl')
    to match your board setup.

    All the code in this project is vendor agnostic (or should be, I have only
    tried it on Quartus and ISE). Specifically, it does not instance memory
    blocks (relying instead on memory inference) or clock managers or buffers.
    This has its drawbacks but is an stated goal of the project -- in the long
    run it pays, I think.


    The memory test demo, on the other hand, uses the external static RAM on
    the DE-1 board. Porting it involves only adapting the memory interface 
    signals and should be quite straightforward. You're on your own, though.
     
4.3 'Adventure' demo

    There is a second demo targeting the same hardware as the hello demo above:
    a port of 'Adventure'. The C source (included) has been slightly modified
    to not use any library functions nor any fulesystem (instead uses a built-in
    constant string table).
    
    Build steps are the same as for the hello demo (the make target is 
    adventure_demo). 
    
    Since the binary executable is too large to fit internal BRAM, it has to be 
    executed from the DE-1 onboard flash. You need to write file adventure.bin
    to the start of the FLASH using the 'Control Panel' tool that came with your
    DE-1 board. That's the only salient difference.
    
    The game will offer you an auto-walkthrough option. Answer 'y' and it will
    play itself for about 250 moves, leaving you at an intermediate stage of 
    the game from which you can play on. 
    
    Running Adventure on a computer built by myself is just something I wanted 
    to do :) besides, it serves a useful purpose as a confidence builder.


5.- Tools
================================================================================


5.1.- MIPS software simulator

    (NOTE: as of rev. 114 the SW simulator has some features not explained here;
    please see the sources for a very brief explaination. I'll update the doc
    ASAP)

    Plasma project includes a MIPS-I simulator made by Steve Rhoads, called
    'mlite.c'. According the the author, it was used as a golden model for the
    construction of the cpu, the same as I have done.
    I have made some modifications on Rhoads' code, mostly for logging, and
    called the new program 'slite' ('/tools/slite/src/slite.c').

    The simulator is a single C file (slite.c) that should be compilable in
    linux and win32 with no changes. I have only tested it in win32/cygwin.

    The program has been hastily modified to accomodate the 'Modified Harvard'
    architecture of the cpu (code and data are in separate buses and RAMs, but
    in the same address spaces, so it's really a Modified Harvard with separate
    storage) -- See section 2.1 about the buses.

    The simulator can be compiled for compatibility to Plasma or to a more
    standard mips1. This affects the simulated memory map and the trap vectors
    only, as of rev. 70. Note that mips1 simulation is far from complete yet.

    Upon startup, the simulator loads a number of binary files as requested in 
    the command line:
    
    --bram=<filename>    : file to be loaded in simulated FPGA block RAM
    --xram=<filename>    : file to be loaded in simulated external RAM
    --flash=<filename>   : file to be loaded in simulated flash area

    For the basic code samples provided, you want to load the code binary on
    the BRAM and the data binary, even if empty, on the XRAM (note that a real
    XRAM is out of the FPGA and thus we can't initialize them 'in logic', we'd 
    have to do it from the start-up SW, which ours doesn't).

    The addresses and attributes (read only, etc.) of the memory blocks are
    hardcoded (though they are parametrizable, see the source) and reflect
    the actual memory map of the target system as defined in mips_pkg.vhdl.

    After loading the binary files, a reset is performed and execution starts
    at 0x00000000 (if compiled for Plasma compatibility) or 0xbfc00000 (if
    compiled for mips1 compatibility).
    
    If you want to simulate a Plasma, you need to compile the code with 
    macro SIMULATE_PLASMA defined, *and* you have to use command line 
    parameter '--plasma'. This makes my life a bit easier.
    
    Simulation of plasma is meant as legacy only; the system will steadily move
    away from compatibility with Plasma but since the simulator started as a
    Plasma-only simulator, I though it may come in handy later to retain
    that capability.
    
    Many system parameters are hardcoded, including the log file name, the
    simulated memory sizes and the code and data addresses.

    The files are assumed to be plain binary chunks of big-endian data that are
    passed directly to the simulated cpu.

    The simulation is logged in a text file with exactly the same format as
    described in 3.2.1. It logs the exact same events so that the log file is
    directly comparable to the modelsim simulation log, as explained in 3.2.

    The hardcoded log file name is "sw_sim_log.txt".



5.2.- Conversion script bin2hdl.py

    This Python script reads two binary files (for the data and code images, as
    explained above) and 'inserts' them in a vhdl template. It makes the
    conversion from binary to vhdl strings and slices the data in byte columns,
    as required by the RAM implementation (in which each byte in a word is
    stored in a different RAM with a separate WE, 4 blocks in all).
    The makefiles of the code samples can be used as an example. The script code
    is simple enough to be understandable even if you don't know Python, and
    includes some usage instructions.

    The vhdl templates (/src/*_template.vhdl) have placeholder 'tags' that are
    replaced with real application data by this script.

    The tags are these:

    "@code0@"               : Contents of RAM block for slice 0 (lsb) of code
       ...
    "@code3@"               : Contents of RAM block for slice 3 (msb) of code
    "@data0@"               : Contents of RAM block for slice 0 (lsb) of data
       ...
    "@data3@"               : Contents of RAM block for slice 3 (msb) of data
    "@entity_name@"         : Name of entity in target vhdl file
    "@arch_name@"           : Name of architecture in target vhdl file
    "@code_table_size@"     : Size of RAM block to be used for code, in words
    "@code_addr_size@"      : ceil(log2(@code_table_size@))
    "@data_table_size@"     : Size of RAM block to be used for data, in words
    "@data_addr_size@"      : ceil(log2(@data_table_size@))

    These placeholders will be replaced with object code or with data values
    provided by the script command line (see makefiles).

    The script has been used with Python 2.6.2. It should work with earlier
    or later versions but I haven't tested.

    Note: all of the above info is in the scrip itself, and can be shown
    with command line option -h. Since it will be more up to date than this 
    doc, you're advised to read the script.


6.- Code samples
================================================================================

Directory /src directory contains a few test applications that can be simulated
and run on real hardware, except for the opcode test which can only be
simulated. See the readme file and the makefile for each program.

The makefiles have been tested with the CodeSourcery toolchain for windows (that
can be downloaded from www.codesourcery.com) and with the Buildroot toolchain
for GNU/Linux.

Most makefiles have two targets, to create a simulation test bench and a
synthesizable demo.

Target '*_sim' (e.g. 'hello_sim') will build the simulation test bench as vhdl
file '/vhdl/tb/mips_tb2.vhdl'. This is the default test bench expected by the
simulation script '/sim/mips_tb2.do'.

The two test benches differ in the memory structure they simulate, please read
the sources (preferably the templates, which will be uncluttered with object 
code).

Target '*_demo' will build a synthesizable demo as '/vhdl/demo/mips_mpu.vhdl'.

The build process will produce two binary files '*.code' and '*.data' that can
be run on the software simulator:

    slite hello.code hello.data

Plus a listing file (*.lst) handy for debugging.


The python script 'bin2hdl.py' is used to insert binary data on vhdl templates.
Assuming you have Python 2.5 or later in your machine, call the script with

    python bin2hdl.py --help

to get a short description (see section 5.2).

(This section is copied in file '/src/readme.txt'.)


REFERENCES 
================================================================================
[1] "See MIPS Run (2nd Edition)"
    D. Sweetman
    Elsevier 2007
    
[2] "IDT R30xx Family Software Reference Manual" 
    Dominic Sweetman
    Idt 1994 (freely available in pdf format)
